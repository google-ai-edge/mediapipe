/* Copyright 2022 The MediaPipe Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
// TODO Refactor naming and class structure of hand related Tasks.
syntax = "proto2";

package mediapipe.tasks.vision.hand_gesture_recognizer.proto;

import "mediapipe/framework/calculator.proto";
import "mediapipe/tasks/cc/components/classifier_options.proto";
import "mediapipe/tasks/cc/core/proto/base_options.proto";

message HandGestureRecognizerSubgraphOptions {
  extend mediapipe.CalculatorOptions {
    optional HandGestureRecognizerSubgraphOptions ext = 463370452;
  }
  // Base options for configuring hand gesture recognition subgraph, such as
  // specifying the TfLite model file with metadata, accelerator options, etc.
  optional core.proto.BaseOptions base_options = 1;

  // Options for configuring the gesture classifier behavior, such as score
  // threshold, number of results, etc.
  optional ClassifierOptions classifier_options = 2;

  // Minimum confidence value ([0.0, 1.0]) for the hand landmarks to be
  // considered tracked successfully
  optional float min_tracking_confidence = 3 [default = 0.0];
}
